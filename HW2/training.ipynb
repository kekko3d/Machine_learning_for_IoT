{"cells":[{"cell_type":"code","source":["!ls requirements.txt\n","!pip install -r requirements.txt\n","import tensorflow_io as tfio\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","from preprocessing import LABELS"],"metadata":{"tags":[],"cell_id":"97a3ca87b695490b829702cadba14429","source_hash":"8b468803","execution_start":1671552542912,"execution_millis":4525,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"C_c7520LXd0a","outputId":"58bd0835-13fd-4815-cfad-fa27cabd4d2c"},"outputs":[{"name":"stdout","text":"requirements.txt\nRequirement already satisfied: ipython==8.5.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (8.5.0)\nCollecting psutil==5.9.2\n  Using cached psutil-5.9.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\nRequirement already satisfied: sounddevice==0.4.5 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.4.5)\nRequirement already satisfied: scipy==1.9.1 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.9.1)\nRequirement already satisfied: redis==4.3.4 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (4.3.4)\nRequirement already satisfied: tensorflow==2.8 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.8.0)\nRequirement already satisfied: tensorflow-io==0.25 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.25.0)\nRequirement already satisfied: cherrypy==18.8.0 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (18.8.0)\nRequirement already satisfied: paho-mqtt==1.6.1 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.6.1)\nRequirement already satisfied: tensorflow-model-optimization==0.7.3 in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (0.7.3)\nRequirement already satisfied: pygments>=2.4.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (2.13.0)\nRequirement already satisfied: traitlets>=5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (5.5.0)\nRequirement already satisfied: matplotlib-inline in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (0.1.6)\nRequirement already satisfied: jedi>=0.16 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (0.17.2)\nRequirement already satisfied: stack-data in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (0.5.1)\nRequirement already satisfied: pexpect>4.3 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (4.8.0)\nRequirement already satisfied: backcall in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (0.2.0)\nRequirement already satisfied: decorator in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (5.1.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (3.0.31)\nRequirement already satisfied: pickleshare in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from ipython==8.5.0->-r requirements.txt (line 1)) (0.7.5)\nRequirement already satisfied: CFFI>=1.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from sounddevice==0.4.5->-r requirements.txt (line 3)) (1.15.1)\nRequirement already satisfied: numpy<1.25.0,>=1.18.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scipy==1.9.1->-r requirements.txt (line 4)) (1.23.4)\nRequirement already satisfied: deprecated>=1.2.3 in /root/venv/lib/python3.9/site-packages (from redis==4.3.4->-r requirements.txt (line 5)) (1.2.13)\nRequirement already satisfied: packaging>=20.4 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from redis==4.3.4->-r requirements.txt (line 5)) (21.3)\nRequirement already satisfied: async-timeout>=4.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from redis==4.3.4->-r requirements.txt (line 5)) (4.0.2)\nRequirement already satisfied: tensorboard<2.9,>=2.8 in /root/venv/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (2.8.0)\nRequirement already satisfied: libclang>=9.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (14.0.6)\nRequirement already satisfied: astunparse>=1.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.6.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/venv/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (0.25.0)\nRequirement already satisfied: h5py>=2.9.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (3.7.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (4.4.0)\nRequirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /root/venv/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (2.8.0.dev2021122109)\nRequirement already satisfied: wrapt>=1.11.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.14.1)\nRequirement already satisfied: google-pasta>=0.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (0.2.0)\nRequirement already satisfied: absl-py>=0.4.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: termcolor>=1.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (2.0.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.50.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.1.2)\nRequirement already satisfied: six>=1.12.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (3.3.0)\nRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /root/venv/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (2.8.0)\nRequirement already satisfied: flatbuffers>=1.12 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (22.9.24)\nRequirement already satisfied: protobuf>=3.9.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (3.19.6)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (58.1.0)\nRequirement already satisfied: gast>=0.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow==2.8->-r requirements.txt (line 6)) (0.4.0)\nRequirement already satisfied: portend>=2.1.1 in /root/venv/lib/python3.9/site-packages (from cherrypy==18.8.0->-r requirements.txt (line 8)) (3.1.0)\nRequirement already satisfied: jaraco.collections in /root/venv/lib/python3.9/site-packages (from cherrypy==18.8.0->-r requirements.txt (line 8)) (3.8.0)\nRequirement already satisfied: cheroot>=8.2.1 in /root/venv/lib/python3.9/site-packages (from cherrypy==18.8.0->-r requirements.txt (line 8)) (9.0.0)\nRequirement already satisfied: more-itertools in /root/venv/lib/python3.9/site-packages (from cherrypy==18.8.0->-r requirements.txt (line 8)) (9.0.0)\nRequirement already satisfied: zc.lockfile in /root/venv/lib/python3.9/site-packages (from cherrypy==18.8.0->-r requirements.txt (line 8)) (2.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /root/venv/lib/python3.9/site-packages (from tensorflow-model-optimization==0.7.3->-r requirements.txt (line 10)) (0.1.8)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.8->-r requirements.txt (line 6)) (0.37.1)\nRequirement already satisfied: pycparser in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from CFFI>=1.0->sounddevice==0.4.5->-r requirements.txt (line 3)) (2.21)\nRequirement already satisfied: jaraco.functools in /root/venv/lib/python3.9/site-packages (from cheroot>=8.2.1->cherrypy==18.8.0->-r requirements.txt (line 8)) (3.5.2)\nRequirement already satisfied: parso<0.8.0,>=0.7.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jedi>=0.16->ipython==8.5.0->-r requirements.txt (line 1)) (0.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.4->redis==4.3.4->-r requirements.txt (line 5)) (3.0.9)\nRequirement already satisfied: ptyprocess>=0.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from pexpect>4.3->ipython==8.5.0->-r requirements.txt (line 1)) (0.7.0)\nRequirement already satisfied: tempora>=1.8 in /root/venv/lib/python3.9/site-packages (from portend>=2.1.1->cherrypy==18.8.0->-r requirements.txt (line 8)) (5.1.0)\nRequirement already satisfied: wcwidth in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython==8.5.0->-r requirements.txt (line 1)) (0.2.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (2.28.1)\nRequirement already satisfied: markdown>=2.6.8 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (3.4.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (0.4.6)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (1.8.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (2.13.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (2.2.2)\nRequirement already satisfied: jaraco.classes in /root/venv/lib/python3.9/site-packages (from jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (3.2.3)\nRequirement already satisfied: jaraco.text in /root/venv/lib/python3.9/site-packages (from jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (3.11.0)\nRequirement already satisfied: asttokens in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from stack-data->ipython==8.5.0->-r requirements.txt (line 1)) (2.0.8)\nRequirement already satisfied: executing in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from stack-data->ipython==8.5.0->-r requirements.txt (line 1)) (1.1.1)\nRequirement already satisfied: pure-eval in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from stack-data->ipython==8.5.0->-r requirements.txt (line 1)) (0.2.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (5.2.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (5.0.0)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (2022.9.24)\nRequirement already satisfied: pytz in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy==18.8.0->-r requirements.txt (line 8)) (2022.5)\nCollecting MarkupSafe>=2.1.1\n  Using cached MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nRequirement already satisfied: inflect in /root/venv/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (6.0.2)\nRequirement already satisfied: jaraco.context>=4.1 in /root/venv/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (4.2.0)\nRequirement already satisfied: autocommand in /root/venv/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (2.2.2)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (3.9.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8->-r requirements.txt (line 6)) (3.2.2)\nRequirement already satisfied: pydantic>=1.9.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from inflect->jaraco.text->jaraco.collections->cherrypy==18.8.0->-r requirements.txt (line 8)) (1.10.2)\nInstalling collected packages: psutil, MarkupSafe\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.9.3\n    Not uninstalling psutil at /shared-libs/python3.9/py-core/lib/python3.9/site-packages, outside environment /root/venv\n    Can't uninstall 'psutil'. No files were found to uninstall.\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /shared-libs/python3.9/py-core/lib/python3.9/site-packages, outside environment /root/venv\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\nSuccessfully installed MarkupSafe-2.1.1 psutil-5.9.2\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m2022-12-20 16:09:06.105707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-12-20 16:09:06.105742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["go_stop_train_ds = tf.data.Dataset.list_files(['msc-train/go*', 'msc-train/stop*'])\n","go_stop_val_ds = tf.data.Dataset.list_files(['msc-val/go*', 'msc-val/stop*'])\n","go_stop_test_ds = tf.data.Dataset.list_files(['msc-test/go*', 'msc-test/stop*'])"],"metadata":{"tags":[],"cell_id":"1b07ac0285204eb7a718baa08b869452","source_hash":"17d168e2","execution_start":1671552550925,"execution_millis":182,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"3wOKx--ZXd0d","outputId":"a6f43602-9803-499b-fce7-6c0aa5a2cf10"},"outputs":[{"name":"stderr","text":"2022-12-20 16:09:10.918474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-12-20 16:09:10.918508: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n2022-12-20 16:09:10.918530: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-59bac526-4289-456d-8cb9-47b42ab71644): /proc/driver/nvidia/version does not exist\n2022-12-20 16:09:10.918891: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["import os\n","import numpy as np\n","import random\n","seed = 42\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","random.seed(seed)\n","np.random.seed(seed)"],"metadata":{"tags":[],"cell_id":"591214f8f1d04121b07485a3133b36f8","source_hash":"ecbfb289","execution_start":1671552553977,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"BMnYUicVXd0d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=[32, 32, 1]),\n","    tf.keras.layers.Conv2D(filters=128, kernel_size=[3, 3], strides=[2, 2],\n","        use_bias=False, padding='valid'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n","        use_bias=False, padding='same'),\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=[1, 1], strides=[1, 1],\n","        use_bias=False, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n","        use_bias=False, padding='same'),\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=[1, 1], strides=[1, 1],\n","        use_bias=False, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Dense(units=len(LABELS)),\n","    tf.keras.layers.Softmax()\n","])"],"metadata":{"tags":[],"cell_id":"ffd75f691f3647a882160bb23417e5d2","source_hash":"c4973dfd","execution_start":1671552557497,"execution_millis":65,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"nQ81AXUXXd0e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from preprocessing import get_audio_and_label\n","from preprocessing import get_spectrogram\n","from preprocessing import get_log_mel_spectrogram\n","from functools import partial\n","TRAINING_ARGS = {\n","    'batch_size': 15,\n","    'epochs': 10,\n","    'initial_learning_rate': 0.01,\n","    'end_learning_rate': 1.e-5,\n","}\n","batch_size = TRAINING_ARGS['batch_size']\n","initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n","end_learning_rate = TRAINING_ARGS['end_learning_rate']\n","epoch = TRAINING_ARGS['epochs']\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n","linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n","    initial_learning_rate=initial_learning_rate,\n","    end_learning_rate=end_learning_rate,\n","    decay_steps= len(go_stop_train_ds) * epoch,\n",")\n","optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n","metrics = [tf.metrics.SparseCategoricalAccuracy()]\n","model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"],"metadata":{"tags":[],"cell_id":"c5afce8be5544c71a62a6e99c4723013","source_hash":"baafc381","execution_start":1671552562385,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"ihtKyWIIXd0e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["for mlf in [20, 50, 80]:\n","    for mul in [2000, 5000, 8000]:\n","        for bin in [10, 20, 30, 40]:\n","            for down_s in [4000, 8000, 16000]:\n","                for frame_l in [0.01, 0.02, 0.04, 0.05]:\n","                    for overlap_perc in [0.25, 0.50, 0.75, 1]:\n","                        overlap = frame_l*(1-overlap_perc)\n","                        SPECTROGRAM_ARGS = {\n","                            'downsampling_rate': down_s,\n","                            'frame_length_in_s': frame_l,\n","                            'frame_step_in_s': overlap\n","                        }\n","                        MEL_LOG_ARGS = {\n","                            'downsampling_rate': down_s,\n","                            'frame_length_in_s': frame_l,\n","                            'frame_step_in_s': frame_l,\n","                            'num_mel_bins': bin,\n","                            'lower_frequency': mlf,\n","                            'upper_frequency': mul,\n","                        }\n","\n","                        def get_spectrogram_and_label(filename, downsampling_rate, frame_length_in_s, frame_step_in_s):\n","                            x, _, label = get_spectrogram(filename, downsampling_rate, frame_length_in_s, frame_step_in_s)\n","                            return x, label\n","                        get_frozen_spectrogram = partial(get_spectrogram_and_label, **SPECTROGRAM_ARGS)\n","                        get_frozen_log_mel_spectrogram = partial(get_log_mel_spectrogram, **MEL_LOG_ARGS)\n","                        SHAPE = [49, 40]\n","\n","                        def preprocess_with_resized_mel(filename):\n","                            signal, label = get_frozen_log_mel_spectrogram(filename)\n","                            signal.set_shape(SHAPE) \n","                            signal = tf.expand_dims(signal, -1)\n","                            signal = tf.image.resize(signal, [32, 32])\n","                            label_id = tf.argmax(label == LABELS)\n","                            return signal, label_id\n","\n","            \n","                        initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n","                        end_learning_rate = TRAINING_ARGS['end_learning_rate']\n","                        epoch = TRAINING_ARGS['epochs']\n","                        train_resized_ds = go_stop_train_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","                        val_ds = go_stop_val_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","                        test_ds = go_stop_test_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","                        loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n","\n","                        linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n","                            initial_learning_rate=initial_learning_rate,\n","                            end_learning_rate=end_learning_rate,\n","                            decay_steps= len(go_stop_train_ds) * epoch,\n","                        )\n","                        optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n","                        metrics = [tf.metrics.SparseCategoricalAccuracy()]\n","                        model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","                        history = model.fit(train_resized_ds, epochs=epoch, validation_data=val_ds)\n","                        test_loss, test_accuracy = model.evaluate(test_ds)\n","                        print(\"test_accuracy\", test_accuracy)\n","                        if test_accuracy > 0.80:\n","                            MODEL_NAME = test_accuracy\n","                            saved_model_dir = f'saved_models/{str(MODEL_NAME)}'\n","                            if not os.path.exists(saved_model_dir):\n","                                os.makedirs(saved_model_dir)\n","                            model.save(saved_model_dir)\n"],"metadata":{"tags":[],"cell_id":"eedf988243a64922b81e9cbf06ca5895","source_hash":"8fef7655","execution_start":1671552565973,"execution_millis":145306,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"hKzwhul0Xd0f","outputId":"0fbbde6f-cf6c-4f42-9529-941147e9637d"},"outputs":[{"name":"stderr","text":"2022-12-20 16:09:26.335058: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n2022-12-20 16:09:26.335277: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 AVX512F FMA\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:09:26.718118: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:26.719597: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:26.719804: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:09:26.975641: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:26.976933: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:26.977161: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:27.229949: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:27.231894: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:09:27.232260: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nEpoch 1/10\n107/107 [==============================] - 13s 114ms/step - loss: 0.5832 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.8515 - val_sparse_categorical_accuracy: 0.5350\nEpoch 2/10\n107/107 [==============================] - 12s 110ms/step - loss: 0.3943 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.7487 - val_sparse_categorical_accuracy: 0.7100\nEpoch 3/10\n107/107 [==============================] - 12s 111ms/step - loss: 0.3493 - sparse_categorical_accuracy: 0.8444 - val_loss: 6.9079 - val_sparse_categorical_accuracy: 0.5000\nEpoch 4/10\n107/107 [==============================] - 12s 113ms/step - loss: 0.3020 - sparse_categorical_accuracy: 0.8687 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7950\nEpoch 5/10\n107/107 [==============================] - 12s 112ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.7763 - val_sparse_categorical_accuracy: 0.6700\nEpoch 6/10\n107/107 [==============================] - 12s 112ms/step - loss: 0.2528 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.2941 - val_sparse_categorical_accuracy: 0.8850\nEpoch 7/10\n107/107 [==============================] - 12s 112ms/step - loss: 0.2851 - sparse_categorical_accuracy: 0.8737 - val_loss: 1.1598 - val_sparse_categorical_accuracy: 0.6850\nEpoch 8/10\n107/107 [==============================] - 12s 112ms/step - loss: 0.2457 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.8050\nEpoch 9/10\n107/107 [==============================] - 12s 111ms/step - loss: 0.2533 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.9050\nEpoch 10/10\n107/107 [==============================] - 12s 110ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.3902 - val_sparse_categorical_accuracy: 0.8200\n14/14 [==============================] - 1s 55ms/step - loss: 0.3526 - sparse_categorical_accuracy: 0.8250\ntest_accuracy 0.824999988079071\n2022-12-20 16:11:32.389239: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nINFO:tensorflow:Assets written to: saved_models/0.824999988079071/assets\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:11:33.101035: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.102478: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.102709: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:11:33.358807: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.360219: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.360436: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.615712: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.617179: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:11:33.617408: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nEpoch 1/10\n107/107 [==============================] - 12s 112ms/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9087 - val_loss: 1.1557 - val_sparse_categorical_accuracy: 0.6400\nEpoch 2/10\n 26/107 [======>.......................] - ETA: 8s - loss: 0.2343 - sparse_categorical_accuracy: 0.9000","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [6], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()]\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m---> 54\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_resized_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/callbacks.py:1107\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1107\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/utils/generic_utils.py:976\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    973\u001b[0m     info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    975\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m--> 976\u001b[0m   \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m   message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/utils/io_utils.py:38\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m   sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[0;32m---> 38\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py-core/lib/python3.9/site-packages/ipykernel/iostream.py:488\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/usr/local/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n","File \u001b[0;32m/usr/local/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":null},{"cell_type":"code","source":["#accordingly to the best accuracy obtained we select the hyperparameters\n","#to use in the following part to fine tune and otmize the model"],"metadata":{"tags":[],"cell_id":"bd0341019fac444281244f96bd817558","source_hash":"bed342df","execution_start":1671532337275,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"VJrL-MSNXd0f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["TRAINING_ARGS = {\n","    'batch_size': 15,\n","    'epochs': 10,\n","    'initial_learning_rate': 0.01,\n","    'end_learning_rate': 1.e-5,\n","}\n","batch_size = TRAINING_ARGS['batch_size']\n","initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n","end_learning_rate = TRAINING_ARGS['end_learning_rate']\n","epoch = TRAINING_ARGS['epochs']"],"metadata":{"cell_id":"cacb1dd4bc124a09886ca5164371600a","source_hash":"f8d4eb7","execution_start":1671552717022,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"Xhv1jdKGXd0g"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from time import time\n","\n","good_param = list()\n","timestamp = time()\n","\n","SPECTROGRAM_ARGS = {\n","    'downsampling_rate': 16000,\n","    'frame_length_in_s': 0.05,\n","    'frame_step_in_s': 0.025\n","}\n","\n","MEL_LOG_ARGS = {\n","    'downsampling_rate': 16000,\n","    'frame_length_in_s': 0.05,\n","    'frame_step_in_s': 0.025,\n","    'num_mel_bins': 30,\n","    'lower_frequency': 20,\n","    'upper_frequency': 8000, \n","}\n","\n","\n","def get_spectrogram_and_label(filename, downsampling_rate, frame_length_in_s, frame_step_in_s):\n","    x, _, label = get_spectrogram(filename, downsampling_rate, frame_length_in_s, frame_step_in_s)\n","    return x, label\n","get_frozen_spectrogram = partial(get_spectrogram_and_label, **SPECTROGRAM_ARGS)\n","get_frozen_log_mel_spectrogram = partial(get_log_mel_spectrogram, **MEL_LOG_ARGS)\n","SHAPE = [49, 40]\n","\n","def preprocess_with_resized_mel(filename):\n","    signal, label = get_frozen_log_mel_spectrogram(filename)\n","    signal.set_shape(SHAPE) \n","    signal = tf.expand_dims(signal, -1)\n","    signal = tf.image.resize(signal, [32, 32])\n","    label_id = tf.argmax(label == LABELS)\n","    return signal, label_id\n","\n","initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n","end_learning_rate = TRAINING_ARGS['end_learning_rate']\n","epoch = TRAINING_ARGS['epochs']\n","train_resized_ds = go_stop_train_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","val_ds = go_stop_val_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","test_ds = go_stop_test_ds.map(preprocess_with_resized_mel).batch(batch_size)\n","\n","\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","begin_step = int(len(train_resized_ds) * epoch * 0.2)\n","end_step = int(len(train_resized_ds) * epoch)\n","alpha_list = [1]\n","final_sparsity_list =[0.70, 0.80, 0.85, 0.95]\n","\n","for alpha in alpha_list:\n","    for final_sparsity in final_sparsity_list:\n","      \n","        model = tf.keras.Sequential([\n","            tf.keras.layers.Input(shape=[32, 32, 1]),\n","            tf.keras.layers.Conv2D(filters=48 * alpha, kernel_size=[3, 3], strides=[2, 2],\n","                use_bias=False, padding='valid'),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.ReLU(),\n","            tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n","                use_bias=False, padding='same'),\n","            tf.keras.layers.Conv2D(filters=48 * alpha, kernel_size=[3, 3], strides=[2, 2],\n","                use_bias=False, padding='valid'),\n","            tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n","                use_bias=False, padding='same'),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.ReLU(),\n","            tf.keras.layers.Conv2D(filters=48 * alpha, kernel_size=[1, 1], strides=[1, 1],\n","                use_bias=False, padding='same'),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.ReLU(),\n","            tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n","                use_bias=False, padding='same'),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.ReLU(),\n","            tf.keras.layers.GlobalAveragePooling2D(),\n","            tf.keras.layers.Dense(units=len(LABELS)),\n","            tf.keras.layers.Softmax()\n","        ])\n","\n","    \n","        #########################################PRUNING#############################################\n","\n","        pruning_params = {\n","            'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n","                initial_sparsity=0.20,\n","                final_sparsity=final_sparsity,\n","                begin_step=begin_step,\n","                end_step=end_step,\n","            )\n","        }\n","        model_for_pruning = prune_low_magnitude(model, **pruning_params)\n","\n","        #########################################DEFINING MODEL#############################################\n","\n","        loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n","        linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n","            initial_learning_rate=initial_learning_rate,\n","            end_learning_rate=end_learning_rate,\n","            decay_steps= len(go_stop_train_ds) * epoch,\n","        )\n","        optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n","        metrics = [tf.metrics.SparseCategoricalAccuracy()]\n","        callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n","        model_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","        history = model_for_pruning.fit(train_resized_ds, epochs=epoch, validation_data=val_ds, callbacks=callbacks, verbose = 2)\n","        test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)\n","        print(\"test_accuracy\", test_accuracy)\n","        print(\"test_loss\", test_loss)\n","        print(alpha, final_sparsity)\n","        if test_accuracy > 0.97:\n","            model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","            #save the model with the accuracy as name\n","            saved_model_dir = f'saved_models_fine_tuning/{str(test_accuracy)}'\n","            if not os.path.exists(saved_model_dir):\n","                os.makedirs(saved_model_dir)\n","            model_for_export.save(saved_model_dir)\n","\n","        "],"metadata":{"cell_id":"ea5636b2c7884c7d9943049fe04cf8d9","source_hash":"17c8cf72","execution_start":1671552856459,"execution_millis":603664,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"oeCXAZlhXd0g","outputId":"e2c9b627-2e64-4263-88da-43906dc5fb39"},"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:14:16.601646: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:16.603237: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:16.603497: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:14:16.876534: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:16.877994: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:16.878231: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n2022-12-20 16:14:17.140264: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:17.141878: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\n2022-12-20 16:14:17.142126: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at functional_ops.cc:374 : INTERNAL: No function library\nEpoch 1/10\n107/107 - 56s - loss: 0.4214 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.4449 - val_sparse_categorical_accuracy: 0.7950 - 56s/epoch - 527ms/step\nEpoch 2/10\n107/107 - 53s - loss: 0.1796 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.3155 - val_sparse_categorical_accuracy: 0.8300 - 53s/epoch - 499ms/step\nEpoch 3/10\n107/107 - 54s - loss: 0.1524 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.1617 - val_sparse_categorical_accuracy: 0.9550 - 54s/epoch - 505ms/step\nEpoch 4/10\n107/107 - 54s - loss: 0.1499 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.1215 - val_sparse_categorical_accuracy: 0.9500 - 54s/epoch - 502ms/step\nEpoch 5/10\n107/107 - 53s - loss: 0.0858 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9450 - 53s/epoch - 500ms/step\nEpoch 6/10\n107/107 - 54s - loss: 0.0619 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1602 - val_sparse_categorical_accuracy: 0.9400 - 54s/epoch - 503ms/step\nEpoch 7/10\n107/107 - 54s - loss: 0.0669 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1602 - val_sparse_categorical_accuracy: 0.9400 - 54s/epoch - 505ms/step\nEpoch 8/10\n107/107 - 54s - loss: 0.0884 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9150 - 54s/epoch - 500ms/step\nEpoch 9/10\n107/107 - 53s - loss: 0.0806 - sparse_categorical_accuracy: 0.9675 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9450 - 53s/epoch - 500ms/step\nEpoch 10/10\n107/107 - 53s - loss: 0.0590 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9550 - 53s/epoch - 499ms/step\n14/14 [==============================] - 6s 408ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9650\ntest_accuracy 0.9649999737739563\ntest_loss 0.0722167044878006\n1 0.7\nWARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nINFO:tensorflow:Assets written to: saved_models_fine_tuning/0.9649999737739563/assets\nEpoch 1/10\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [11], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mUpdatePruningStep()]\n\u001b[1;32m    104\u001b[0m model_for_pruning\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m--> 105\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_for_pruning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_resized_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model_for_pruning\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/engine/training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/engine/training.py:1710\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1709\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_test_begin()\n\u001b[0;32m-> 1710\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   1712\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/keras/engine/data_adapter.py:1191\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1191\u001b[0m   data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:486\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    485\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:755\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    751\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 755\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    784\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v2(\n\u001b[1;32m    785\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    786\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m   \u001b[38;5;66;03m# Delete the resource when this object is deleted\u001b[39;00m\n\u001b[1;32m    789\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_deleter \u001b[38;5;241m=\u001b[39m IteratorResourceDeleter(\n\u001b[1;32m    790\u001b[0m       handle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[1;32m    791\u001b[0m       deleter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3315\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3314\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3315\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3318\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":null},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models_fine_tuning/{str(test_accuracy)}')\n","tflite_model = converter.convert()\n","tflite_models_dir = './tflite_models_fine_tuning'\n","\n","if not os.path.exists(tflite_models_dir):\n","    os.makedirs(tflite_models_dir)\n","\n","tflite_model_name = os.path.join(tflite_models_dir, f'{str(test_accuracy)}.tflite')\n","with open(tflite_model_name, 'wb') as fp:\n","    fp.write(tflite_model)\n","\n","import zipfile\n","not_pruned_tflite = os.path.join(tflite_models_dir, f'{test_accuracy}.tflite')\n","with zipfile.ZipFile(f'{not_pruned_tflite}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(not_pruned_tflite)    \n","tflite_size = os.path.getsize(tflite_model_name) / 1024.0\n","zipped_size = os.path.getsize(f'{tflite_model_name}.zip') / 1024.0\n","\n","print(f'Original tflite size (not pruned model): {tflite_size:.3f} KB')\n","print(f'Zipped tflite size (pruned model): {zipped_size:.3f} KB')"],"metadata":{"cell_id":"36c5d808b6fe44c88771a98f239909f2","source_hash":"bd0a3e83","execution_start":1671553467646,"execution_millis":566,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code","id":"oMMuRf50Xd0h","outputId":"e96b0500-c3f5-4b2e-bafc-0dcc8ffddbce"},"outputs":[{"name":"stdout","text":"Original tflite size (not pruned model): 103.746 KB\nZipped tflite size (pruned model): 44.480 KB\n2022-12-20 16:24:28.053173: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n2022-12-20 16:24:28.053215: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n2022-12-20 16:24:28.053924: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./saved_models_fine_tuning/0.9649999737739563\n2022-12-20 16:24:28.056869: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n2022-12-20 16:24:28.056893: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: ./saved_models_fine_tuning/0.9649999737739563\n2022-12-20 16:24:28.063772: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n2022-12-20 16:24:28.101971: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./saved_models_fine_tuning/0.9649999737739563\n2022-12-20 16:24:28.117053: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 63131 microseconds.\n2022-12-20 16:24:28.139118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=59bac526-4289-456d-8cb9-47b42ab71644' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"],"metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","id":"IS58V0RDXd0h"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"vscode":{"interpreter":{"hash":"31dc532d308df201211acc87d8350716fd9607c7c7c4cda0c7a46f6e781b5078"}},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"py310"},"language_info":{"name":"python","version":"3.10.7","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"orig_nbformat":2,"deepnote_notebook_id":"7e82d5ebd87843fcae57bb628628c8b0","deepnote_execution_queue":[],"colab":{"provenance":[]}}}